{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98dd5b97",
   "metadata": {},
   "source": [
    "## Transformer - Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1664af01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc6bf19b110>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Semilla de reproducibilidad\n",
    "torch.manual_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09e58320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe695b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3289ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = MAX_SEQ_LEN):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        # mask para el padding\n",
    "        pass\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x, encoder_output, target_mask, encoder_mask):\n",
    "        # cross-attention\n",
    "        # Necesitamos el encoder_mask para no atender a los maskings\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, input_vocab_size, target_vocab_size,\n",
    "                max_len=MAX_SEQ_LEN, dropout=0.1):\n",
    "        # d_model: Tamaño de los embeddings\n",
    "        # num_heads: Número de cabezas paralelas de atención\n",
    "        # d_ff: Tamaño de las redes neuronales Feed-Forward\n",
    "        # num_layers: Número de capas secuenciales tanto para el encoder como para el decoder\n",
    "        # input_vocab_size\n",
    "        # target_vocab_size\n",
    "        # max_len: Tamaño de la ventana de contexto\n",
    "        \n",
    "        super().__init__()\n",
    "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n",
    "        self.Encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
    "        self.Decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
    "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
    "        \n",
    "    def forward(self, source, target):\n",
    "        sorce_mask, target_mask = self.mask(source, target)\n",
    "        \n",
    "    def mask(self, source, target):\n",
    "        # El token de 0 es de padding\n",
    "        # El resto o bien son tokens especiales (<SOS>, <EOS>) o bien palabras (Aqui cada palabra equivale a un token)\n",
    "        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n",
    "        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n",
    "        size = target.size(1)  # La dimensión 1 representa la longitud de la secuencia (max_seq_len)\n",
    "        no_mask = torch.tril(torch.ones(1, size, size), device=device).bool() # Para evitar ver palabras futuras que aún no se han generado\n",
    "        target_mask = target_mask & no_mask\n",
    "        return source_mask, target_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
