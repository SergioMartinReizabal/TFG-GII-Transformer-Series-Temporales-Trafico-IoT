{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe813297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f84047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VentanaFlowMultiCsvDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lee múltiples CSV y realiza:\n",
    "      1) Concatenación de DataFrames\n",
    "      2) Limpieza de inf/NaN\n",
    "      3) Normalización de columnas numéricas\n",
    "      4) Agrupación por Ventana_Inicio y orden por Timestamp\n",
    "      5) Truncado/padding a max_seq_len\n",
    "      6) Asignación de etiqueta (Label) a cada ventana\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_paths, max_seq_len=50, drop_cols=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "        # Columnas que no queremos en las features\n",
    "        # (Flow ID, IPs, Puerto, Protocol, Timestamp, Label, etc.)\n",
    "        if drop_cols is None:\n",
    "            drop_cols = [\n",
    "                'Ventana_Inicio', 'Flow ID', 'Src IP', 'Src Port',\n",
    "                'Dst IP', 'Dst Port', 'Protocol', 'Timestamp',\n",
    "                'Label'\n",
    "            ]\n",
    "        self.drop_cols = drop_cols\n",
    "        \n",
    "        # 1) Leer y unir todos los CSV\n",
    "        all_dfs = []\n",
    "        for label_name, path_csv in csv_paths.items():\n",
    "            print(f\"[INFO] Leyendo {path_csv} con label='{label_name}'\")\n",
    "            df_temp = pd.read_csv(path_csv)\n",
    "\n",
    "            # Si no existe columna Label, la creamos\n",
    "            if 'Label' not in df_temp.columns:\n",
    "                df_temp['Label'] = label_name\n",
    "\n",
    "            all_dfs.append(df_temp)\n",
    "\n",
    "        df = pd.concat(all_dfs, ignore_index=True)\n",
    "        print(\"[INFO] Total de filas tras concatenar:\", df.shape[0])\n",
    "        \n",
    "        # 2) Reemplazar inf/-inf por NaN, y dropna\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"[INFO] Filas restantes tras eliminar inf/NaN:\", df.shape[0])\n",
    "        \n",
    "        # 3) Identificar clases únicas\n",
    "        unique_labels = df['Label'].unique().tolist()\n",
    "        print(\"Clases detectadas:\", unique_labels)\n",
    "        self.label_to_idx = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
    "        \n",
    "        # 4) Normalizar columnas numéricas\n",
    "        #    - Eliminamos temporalmente 'drop_cols' + 'Label' para obtener sólo features numéricas\n",
    "        features_df = df.drop(columns=self.drop_cols, errors='ignore')\n",
    "        \n",
    "        # Asegurarnos de que sean todas numéricas\n",
    "        numeric_cols = features_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        features_df = features_df[numeric_cols]\n",
    "\n",
    "        # Hacemos scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_values = scaler.fit_transform(features_df.values)\n",
    "        scaled_df = pd.DataFrame(scaled_values, columns=numeric_cols, index=features_df.index)\n",
    "        \n",
    "        # Volvemos a adjuntar Label y Ventana_Inicio a df\n",
    "        df[numeric_cols] = scaled_df  # Reemplazamos en df con las columnas escaladas\n",
    "\n",
    "        # 5) Agrupar por 'Ventana_Inicio'\n",
    "        grouped = df.groupby('Ventana_Inicio')\n",
    "        \n",
    "        self.samples = []\n",
    "        for ventana_id, subdf in grouped:\n",
    "            # Ordenar por 'Timestamp' (si existe)\n",
    "            if 'Timestamp' in subdf.columns:\n",
    "                subdf = subdf.sort_values(by='Timestamp', ascending=True)\n",
    "            \n",
    "            # Etiqueta de la ventana\n",
    "            label_val = subdf['Label'].iloc[0]\n",
    "            label_idx = self.label_to_idx[label_val]\n",
    "\n",
    "            # Quitamos columnas no deseadas (incl. Label) para quedarnos solo con features\n",
    "            subdf_features = subdf.drop(columns=self.drop_cols, errors='ignore')\n",
    "            \n",
    "            # Convertir a float32\n",
    "            arr = subdf_features.to_numpy(dtype=np.float32, copy=True)\n",
    "            \n",
    "            # Truncado\n",
    "            if arr.shape[0] > self.max_seq_len:\n",
    "                arr = arr[:self.max_seq_len, :]\n",
    "            # Padding\n",
    "            elif arr.shape[0] < self.max_seq_len:\n",
    "                pad_len = self.max_seq_len - arr.shape[0]\n",
    "                pad_arr = np.zeros((pad_len, arr.shape[1]), dtype=np.float32)\n",
    "                arr = np.concatenate((arr, pad_arr), axis=0)\n",
    "            \n",
    "            self.samples.append((arr, label_idx))\n",
    "        \n",
    "        print(f\"[INFO] Total de ventanas tras agrupar: {len(self.samples)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        arr, lbl_idx = self.samples[idx]\n",
    "        x_tensor = torch.from_numpy(arr)  # shape (max_seq_len, num_features)\n",
    "        y_tensor = torch.tensor(lbl_idx, dtype=torch.long)\n",
    "        return x_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1af2fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model=512, num_heads=8):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, 'El tamaño de embedding debe ser divisible entre num_heads.'\n",
    "        \n",
    "        self.d_v = d_model // num_heads\n",
    "        self.d_k = self.d_v\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "        \n",
    "        # 1) Proyectamos Q, K, V\n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # 2) Calculamos los scores de atención\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # 3) Mezclamos valores\n",
    "        weighted_values = torch.matmul(attention, V)\n",
    "        \n",
    "        # 4) Reorganizamos y aplicamos la proyección de salida\n",
    "        weighted_values = weighted_values.transpose(1, 2).contiguous()\n",
    "        weighted_values = weighted_values.view(batch_size, -1, self.num_heads * self.d_k)\n",
    "        out = self.W_o(weighted_values)\n",
    "        \n",
    "        return out, attention\n",
    "\n",
    "class PositionFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "class EncoderSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # 1) Self-attention\n",
    "        attn_out, _ = self.self_attn(x, x, x, mask)\n",
    "        x = x + self.dropout1(attn_out)  # skip connection\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        # 2) Feed-forward\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + self.dropout2(ffn_out)  # skip connection\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderSubLayer(d_model, num_heads, d_ff, dropout) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        pos_embed = torch.zeros(max_seq_len, d_model)\n",
    "        token_pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pos_embed[:, 0::2] = torch.sin(token_pos * div_term)\n",
    "        pos_embed[:, 1::2] = torch.cos(token_pos * div_term)\n",
    "        \n",
    "        pos_embed = pos_embed.unsqueeze(0)  # (1, max_seq_len, d_model)\n",
    "        self.register_buffer('pos_embed', pos_embed)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        # x shape: (B, seq_len, d_model)\n",
    "        return x + self.pos_embed[:, :seq_len, :]\n",
    "\n",
    "class TransformerEncoderClassifierWithCLS(nn.Module):\n",
    "    \"\"\"\n",
    "    Agrega un token [CLS] entrenable al inicio de la secuencia.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, input_dim, num_classes,\n",
    "                 max_seq_len=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1) Proyección lineal\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # 2) Token CLS entrenable\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, d_model))\n",
    "        \n",
    "        # 3) Embedding posicional\n",
    "        self.pos_embedding = PositionalEmbedding(d_model, max_seq_len)\n",
    "        \n",
    "        # 4) Encoder\n",
    "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
    "        \n",
    "        # 5) Capa final de clasificación\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        x: (B, seq_len, input_dim)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # (A) Proyectamos la entrada\n",
    "        x = self.input_projection(x)  # (B, seq_len, d_model)\n",
    "        \n",
    "        # (B) Preparamos CLS token\n",
    "        cls_tokens = self.cls_token.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        \n",
    "        # (C) Concatenamos CLS al inicio\n",
    "        x = torch.cat([cls_tokens, x], dim=1)  # (B, seq_len+1, d_model)\n",
    "        \n",
    "        # (D) Embedding posicional\n",
    "        x = self.pos_embedding(x)  # (B, seq_len+1, d_model)\n",
    "        \n",
    "        # (E) Encoder\n",
    "        x = self.encoder(x, mask)  # (B, seq_len+1, d_model)\n",
    "        \n",
    "        # (F) El vector CLS es la posición 0\n",
    "        cls_vector = x[:, 0, :]  # (B, d_model)\n",
    "        \n",
    "        # (G) Clasificación final\n",
    "        logits = self.classifier(cls_vector)  # (B, num_classes)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc9b47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, clip_grad_norm=None):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_x, batch_y in dataloader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch_x)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Si quieres hacer gradient clipping (por si hay inestabilidad):\n",
    "        if clip_grad_norm is not None:\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in dataloader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a742c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Leyendo ./Benigno_0.csv con label='BENIGN'\n",
      "[INFO] Leyendo ./DDoS-ICMP_0.csv con label='DDoS-ICMP'\n",
      "[INFO] Total de filas tras concatenar: 419366\n",
      "[INFO] Filas restantes tras eliminar inf/NaN: 419329\n",
      "Clases detectadas: ['Benigno', 'DDoS-ICMP']\n",
      "[INFO] Total de ventanas tras agrupar: 7088\n",
      "input_dim = 76\n",
      "num_classes = 2\n",
      "Epoch [1/5] Train Loss: 0.0489 | Val Loss: 0.0252 | Val Acc: 99.58%\n",
      "Epoch [2/5] Train Loss: 0.0178 | Val Loss: 0.0145 | Val Acc: 99.65%\n",
      "Epoch [3/5] Train Loss: 0.0137 | Val Loss: 0.0241 | Val Acc: 99.51%\n",
      "Epoch [4/5] Train Loss: 0.0083 | Val Loss: 0.0222 | Val Acc: 99.58%\n",
      "Epoch [5/5] Train Loss: 0.0074 | Val Loss: 0.0238 | Val Acc: 99.65%\n",
      "Entrenamiento finalizado.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Diccionario con tus CSV, uno por clase\n",
    "    csv_paths = {\n",
    "        \"BENIGN\":[\n",
    "            \"./Benigno_0.csv\",\n",
    "            \"./Benign_1.csv\",\n",
    "            \"./Benign_2.csv\",\n",
    "            \"./Benign_3.csv\"\n",
    "        ],\n",
    "        \"DDoS-ICMP\":   \"./DDoS-ICMP_0.csv\",\n",
    "        # Agrega más si los tienes...\n",
    "    }\n",
    "    \n",
    "    # 1) Crear dataset con max_seq_len=50\n",
    "    dataset = VentanaFlowMultiCsvDataset(csv_paths, max_seq_len=50)\n",
    "    \n",
    "    # 2) Split train / val\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size   = len(dataset) - train_size\n",
    "    \n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # 3) DataLoader\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # 4) Obtenemos input_dim y num_classes\n",
    "    sample_x, sample_y = dataset[0]\n",
    "    input_dim = sample_x.shape[1]  # (seq_len, n_features)\n",
    "    num_classes = len(dataset.label_to_idx)\n",
    "    \n",
    "    print(\"input_dim =\", input_dim)\n",
    "    print(\"num_classes =\", num_classes)\n",
    "    \n",
    "    # 5) Instanciamos el Transformer con CLS\n",
    "    d_model   = 64\n",
    "    num_heads = 4\n",
    "    d_ff      = 128\n",
    "    num_layers= 2\n",
    "    dropout   = 0.1\n",
    "    \n",
    "    # Ponemos max_seq_len=51 o > 50 para no tener problemas \n",
    "    # (50 flujos + 1 token CLS). Aquí optamos por 128 de sobra:\n",
    "    pos_embed_len = 128\n",
    "    \n",
    "    model = TransformerEncoderClassifierWithCLS(\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        d_ff=d_ff,\n",
    "        num_layers=num_layers,\n",
    "        input_dim=input_dim,\n",
    "        num_classes=num_classes,\n",
    "        max_seq_len=pos_embed_len,  \n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "    \n",
    "    # 6) Configurar pérdida y optimizador\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # 7) Entrenar\n",
    "    epochs = 5\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion,\n",
    "                                     clip_grad_norm=1.0)  # si deseas clipping\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "        \n",
    "        print(f\"Epoch [{epoch}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Val Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    print(\"Entrenamiento finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab5298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
